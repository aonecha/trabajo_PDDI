# Inferencia de Topolog√≠a a partir de Se√±ales sobre Grafos  
**Trabajo Final ‚Äì Procesamiento de Datos Distribuidos e Inferencia (PDDI)**  
Universidad Rey Juan Carlos

---

## Descripci√≥n del proyecto

Este proyecto aborda el problema de la **inferencia de la topolog√≠a de un grafo a partir de se√±ales observadas en sus nodos**, en el marco del **Graph Signal Processing (GSP)** y los **modelos gr√°ficos gaussianos**.

Concretamente, se estudia la inferencia de la estructura del grafo \( S \) utilizando **Graphical Lasso** y m√©todos de inferencia basados en la hip√≥tesis de **se√±ales estacionarias sobre grafos**. El an√°lisis se realiza mediante datos sint√©ticos generados sobre distintos modelos de grafos.

---

## Objetivo

El objetivo principal es:

- **Inferir la estructura del grafo \( S \)** a partir de se√±ales observadas en los nodos.
- Evaluar el rendimiento de distintos m√©todos de inferencia de topolog√≠a.
- Analizar la sensibilidad de los m√©todos frente a distintos par√°metros del problema.

---

## Generaci√≥n de datos

### üîπ Grafos sint√©ticos
Se generan grafos no dirigidos de tama√±o aproximado \( N = 20 \) y \( N = 100 \) nodos, con un grado medio cercano a 4‚Äì6 enlaces por nodo, utilizando distintos modelos:

- Erd≈ës‚ÄìR√©nyi (ER)
- Small-World (SW)
- Barab√°si‚ÄìAlbert (BA)

---

### üîπ Modelos de se√±ales

Se consideran dos tipos de se√±ales:

1. **Se√±ales Gaussianas i.i.d.**
  x ~ N(0, S^{-1})

2. **Se√±ales estacionarias sobre grafos**
   x = H w,   w ~ N(0, I)

   donde \( H \) es un filtro paso bajo definido sobre el grafo.

---

## Algoritmos e implementaci√≥n

El proyecto pone √©nfasis en la **implementaci√≥n de los algoritmos**, m√°s que en su simple evaluaci√≥n.

Se estudian y comparan distintas estrategias para la inferencia de grafos:

- **Graphical Lasso**
- Implementaci√≥n mediante **CVXPY**
- Algoritmos iterativos cl√°sicos:
  - Descenso por gradiente proyectado
  - Descenso coordinado para Graphical Lasso

El objetivo es comparar el impacto de distintas implementaciones sobre el rendimiento y el coste computacional.

---

## M√©tricas y an√°lisis de sensibilidad

Para evaluar la calidad de la inferencia se utilizan las siguientes m√©tricas:

- **Tiempo de c√≥mputo** para la estimaci√≥n del grafo.
- **Error de estimaci√≥n del grafo**, definido como:

  Err(S, ≈ú) = || ≈ú ‚àí S ||_F / || S ||_F
  donde ||¬∑||_F denota la norma de Frobenius.

---

### An√°lisis de sensibilidad

El rendimiento de los m√©todos se analiza en funci√≥n de:

- N√∫mero de muestras disponibles.
- N√∫mero de nodos del grafo.
- Nivel de esparsidad del grafo.
- Tipo de grafo subyacente.
- Posible extensi√≥n a casos m√°s realistas.

---

## Estructura del proyecto

  trabajo_PDDI/

  ‚îú‚îÄ‚îÄ data_generation.py

  ‚îú‚îÄ‚îÄ methods.py

  ‚îú‚îÄ‚îÄ metrics.py

  ‚îú‚îÄ‚îÄ experiments.py

  ‚îú‚îÄ‚îÄ experiments_big.py

  ‚îú‚îÄ‚îÄ plot_error_time_vs_M_all_graphs.py

  ‚îú‚îÄ‚îÄ requirements.txt

  ‚îú‚îÄ‚îÄ figures/

  ‚îî‚îÄ‚îÄ figures_interpretation/

---

## Descripci√≥n de los archivos

### `data_generation.py`
Contiene funciones para:

- Generaci√≥n de grafos:
  - Erd≈ës‚ÄìR√©nyi (ER)
  - Watts‚ÄìStrogatz (Small-World)
  - Barab√°si‚ÄìAlbert (Scale-Free)
- Generaci√≥n de se√±ales:
  - Modelo gaussiano basado en la matriz de precisi√≥n
  - Se√±ales estacionarias mediante filtros laplacianos
- C√°lculo de Laplacianos y matrices de precisi√≥n verdaderas

---

### `methods.py`
Implementa los m√©todos de inferencia de la matriz de precisi√≥n:

- **Ridge** (baseline mediante inversi√≥n regularizada)
- **Graphical Lasso (sklearn)**
- **Graphical Lasso (CVXPY)** con cacheo del problema
- **Projected Gradient Descent (PGD)**

Incluye tambi√©n el c√°lculo de la covarianza muestral centrada.

---

### `metrics.py`
Define las m√©tricas de evaluaci√≥n:

- Error relativo de Frobenius (solo fuera de la diagonal)
- Error relativo de Frobenius completo (para Laplacianos)
- Esparsidad fuera de la diagonal
- Conversi√≥n de Œò estimada a Laplaciano
- (Opcional) F1-score del soporte del grafo

---

### `experiments.py`
Script principal de experimentaci√≥n:

- Generaci√≥n y visualizaci√≥n de grafos ER, SW y BA
- Ejecuciones individuales comparando m√©todos sobre el mismo grafo
- Barridos experimentales:
  - Error y tiempo vs n√∫mero de muestras (M)
  - Error y esparsidad vs par√°metro de regularizaci√≥n (Œª)
- Soporte para se√±ales gaussianas y estacionarias


## Reproducibilidad de los resultados

Esta secci√≥n describe los pasos necesarios para **reproducir todos los resultados del proyecto** a partir del repositorio.

1.  Instalar las dependencias:

pip install -r requirements.txt

2. Ejecuci√≥n de los experimentos

a) Experimentos est√°ndar (grafos peque√±os)
Ejecuta todos los experimentos sobre grafos ER, Small-World y Barab√°si‚ÄìAlbert, considerando se√±ales gaussianas y estacionarias, as√≠ como barridos en el n√∫mero de muestras y el par√°metro de regularizaci√≥n.

python experiments.py
Resultados obtenidos:

M√©tricas de error, esparsidad y tiempo por consola

Figuras de los grafos generados en figures/

b) Experimento a gran escala
Ejecuta un experimento m√°s exigente para evaluar el rendimiento computacional de los m√©todos sobre un grafo grande.

python experiments_big.py
Configuraci√≥n utilizada:

Grafo Erd≈ës‚ÄìR√©nyi

N = 100 nodos

M = 500 muestras

Los resultados se muestran por consola.

3. Generaci√≥n de las figuras finales
Para reproducir todas las gr√°ficas presentadas en el an√°lisis (error, tiempo, esparsidad y frentes de Pareto), ejecutar:

python plot_error_time_vs_M_all_graphs.py

Figuras de los grafos generados en figures_interpretation/