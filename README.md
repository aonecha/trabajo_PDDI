# Proyecto_PDDI

Este proyecto implementa un conjunto de **experimentos de aprendizaje de estructura en grafos** a partir de seÃ±ales observadas, comparando distintos mÃ©todos de estimaciÃ³n de la **matriz de precisiÃ³n (Î˜)** y del **Laplaciano del grafo**.

Se estudia el compromiso entre **precisiÃ³n**, **esparsidad** y **coste computacional** bajo diferentes tipos de grafos, modelos de seÃ±al y parÃ¡metros experimentales.

---

## ğŸ“ Estructura del proyecto

.
â”œâ”€â”€ data_generation.py
â”œâ”€â”€ methods.py
â”œâ”€â”€ metrics.py
â”œâ”€â”€ experiments.py
â”œâ”€â”€ experiments_big.py
â”œâ”€â”€ plot_error_time_vs_M_all_graphs.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ figures/
â””â”€â”€ figures_interpretation/

yaml
Copiar cÃ³digo

---

## ğŸ“Œ DescripciÃ³n de los archivos

### `data_generation.py`
Contiene funciones para:

- GeneraciÃ³n de grafos:
  - ErdÅ‘sâ€“RÃ©nyi (ER)
  - Wattsâ€“Strogatz (Small-World)
  - BarabÃ¡siâ€“Albert (Scale-Free)
- GeneraciÃ³n de seÃ±ales:
  - Modelo gaussiano basado en la matriz de precisiÃ³n
  - SeÃ±ales estacionarias mediante filtros laplacianos
- CÃ¡lculo de Laplacianos y matrices de precisiÃ³n verdaderas

---

### `methods.py`
Implementa los mÃ©todos de inferencia de la matriz de precisiÃ³n:

- **Ridge** (baseline mediante inversiÃ³n regularizada)
- **Graphical Lasso (sklearn)**
- **Graphical Lasso (CVXPY)** con cacheo del problema
- **Projected Gradient Descent (PGD)**

Incluye tambiÃ©n el cÃ¡lculo de la covarianza muestral centrada.

---

### `metrics.py`
Define las mÃ©tricas de evaluaciÃ³n:

- Error relativo de Frobenius (solo fuera de la diagonal)
- Error relativo de Frobenius completo (para Laplacianos)
- Esparsidad fuera de la diagonal
- ConversiÃ³n de Î˜ estimada a Laplaciano
- (Opcional) F1-score del soporte del grafo

---

### `experiments.py`
Script principal de experimentaciÃ³n:

- GeneraciÃ³n y visualizaciÃ³n de grafos ER, SW y BA
- Ejecuciones individuales comparando mÃ©todos sobre el mismo grafo
- Barridos experimentales:
  - Error y tiempo vs nÃºmero de muestras (M)
  - Error y esparsidad vs parÃ¡metro de regularizaciÃ³n (Î»)
- Soporte para seÃ±ales gaussianas y estacionarias


### `EjecuciÃ³n`
## ğŸ” Reproducibilidad de los resultados

Esta secciÃ³n describe los pasos necesarios para **reproducir todos los resultados del proyecto** a partir del repositorio.

1ï¸âƒ£ Requisitos

- Python â‰¥ 3.10
- Sistema operativo: Linux / macOS / Windows
- Se recomienda el uso de un entorno virtual

Instalar las dependencias:

bash
pip install -r requirements.txt

2ï¸âƒ£ EjecuciÃ³n de los experimentos

a) Experimentos estÃ¡ndar (grafos pequeÃ±os)
Ejecuta todos los experimentos sobre grafos ER, Small-World y BarabÃ¡siâ€“Albert, considerando seÃ±ales gaussianas y estacionarias, asÃ­ como barridos en el nÃºmero de muestras y el parÃ¡metro de regularizaciÃ³n.

bash
Copiar cÃ³digo
python experiments.py
Resultados obtenidos:

MÃ©tricas de error, esparsidad y tiempo por consola

Figuras de los grafos generados en figures/

b) Experimento a gran escala
Ejecuta un experimento mÃ¡s exigente para evaluar el rendimiento computacional de los mÃ©todos sobre un grafo grande.

bash
Copiar cÃ³digo
python experiments_big.py
ConfiguraciÃ³n utilizada:

Grafo ErdÅ‘sâ€“RÃ©nyi

N = 100 nodos

M = 500 muestras

Los resultados se muestran por consola.

3ï¸âƒ£ GeneraciÃ³n de las figuras finales
Para reproducir todas las grÃ¡ficas presentadas en el anÃ¡lisis (error, tiempo, esparsidad y frentes de Pareto), ejecutar:

bash
Copiar cÃ³digo
python plot_error_time_vs_M_all_graphs.py
Las figuras se generan automÃ¡ticamente en el directorio:

Copiar cÃ³digo
figures_interpretation/